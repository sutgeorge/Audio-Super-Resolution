import os
VCTK_DATASET_SAMPLING_RATE = 48000
RESAMPLING_FACTOR = 4
STAGE = 7
VERSION = 1
MINIMUM = -32768
MAXIMUM = 32767
DOWNSAMPLED_RATE = int(VCTK_DATASET_SAMPLING_RATE / RESAMPLING_FACTOR)
SAMPLE_DIMENSION = 4096
OVERLAP = 2048
LOW_RESOLUTION_DIMENSION = int(SAMPLE_DIMENSION / RESAMPLING_FACTOR)
LEARNING_RATE = 0.0001
NUMBER_OF_EPOCHS = 10 #100
NUMBER_OF_FILES = len(os.listdir("preprocessed_dataset/low_res/")) # The data that is used is from the set of chunks generated from the first 1000 tracks, which contains approximately 65000 pairs of low-res/high-res patches of 1200/4800 samples
AMOUNT_OF_TRACKS_USED_FOR_DATA_GENERATION = 1000
TRAINING_DATA_SPLIT_PERCENTAGE = 0.8
VALIDATION_DATA_SPLIT_PERCENTAGE = 0.1
TESTING_DATA_SPLIT_PERCENTAGE = 0.1
NUMBER_OF_TRAINING_TENSORS = int(TRAINING_DATA_SPLIT_PERCENTAGE * NUMBER_OF_FILES)
NUMBER_OF_VALIDATION_TENSORS = int(VALIDATION_DATA_SPLIT_PERCENTAGE * NUMBER_OF_FILES)
NUMBER_OF_TESTING_TENSORS = int(TESTING_DATA_SPLIT_PERCENTAGE * NUMBER_OF_FILES)
BATCH_SIZE = 16  # The number of input tensors should be divisible by the batch size
CHECKPOINT_PATH = "checkpoints/checkpoint-epoch-{epoch:04d}-mse_validation_loss-{val_loss:10f}-nrmse_val-{val_normalised_root_mean_squared_error:10f}.ckpt"
CHECKPOINT_DIRECTORY = os.path.dirname(CHECKPOINT_PATH)
NUMBER_OF_PROCESSES = 4
AMOUNT_OF_TRACKS_IN_A_DATA_GENERATION_BATCH = 1000
MODEL_PATH = "models/model_stage_6_version_1_resampling_factor_4_overlap_2048_sample_dimension_4096_epochs_100_batch_size_16_learning_rate_0.0001_data_split_61883_7735_7735.h5"

TRAINING_SET_MEAN = -0.08101532
TRAINING_SET_STD = 1809.791
TRAINING_SET_MIN = -32748
TRAINING_SET_MAX = 32737
TRAINING_SET_FIRST_QUANTILE = -255
TRAINING_SET_SECOND_QUANTILE = -11
TRAINING_SET_THIRD_QUANTILE = 193

